# **Unity 自研 3D 材质生成大模型 | 支付宝推出 Style Tokenizer|LinFusion 高效生成 16K 图像【AI 周报】**

https://mmbiz.qpic.cn/sz_mmbiz_png/NM6DecUSXYtWYIE9aUXFP1YiaWE4UoQCz0MUrkqRNap6WlMeYABdXSgmxsnKAibk0GwZicjt1HX0nCTjVO6HYpzAQ/0?wx_fmt=png&from=appmsg

## **目录**

1. DepthCrafter: 为开放世界视频生成一致的长深度序列
2. LinFusion: 高效生成 16K 图像的新方法
3. Mini-Omni: 实时语音对话模型
4. StyleTokenizer: 控制 Diffusion 模型的图像风格生成
5. HiPrompt: 强化提示词优化框架
6. Geometry Image Diffusion: 基于图像的高效文本生成 3D 模型
7. Guide-and-Rescale: 实现无调优高效图像编辑的自引导机制

## **DepthCrafter: 为开放世界视频生成一致的长深度序列**

![](https://mmbiz.qlogo.cn/sz_mmbiz_jpg/NM6DecUSXYtWYIE9aUXFP1YiaWE4UoQCznCbr3cdbceic814MiboKMW5OT1pU2JBkRbARStnK85vDJ3JXPJTZcRhQ/0?wx_fmt=jpeg&from=appmsg)

**概要**: DepthCrafter [1][2]  提出了一种基于条件扩散模型的视频深度估计方法，能够从开放世界视频生成时间一致的长深度序列，无需相机位姿或光流。通过在现实和合成数据集上进行三阶段训练，模型可以处理长达 110 帧的视频，并采用分段推理策略来无缝生成更长的视频深度序列。

**标签**: #视频深度估计 #开放世界 #视频处理 #Diffusion 模型

## **LinFusion: 高效生成 16K 图像的新方法**

**概要**: LinFusion [3][4]  是由新加坡国立大学 Learning and Vision Lab 提出的创新  Diffusion  模型。它使用线性复杂度的注意力机制，显著减少时间和内存占用，实现高效图像生成，尤其在高分辨率（如 16K 图像）生成上表现出色。LinFusion 在保留预训练模型（如 Stable Diffusion）的基础上，通过知识蒸馏进行优化，兼容 ControlNet 等现有组件，且只需少量训练即可达到甚至超越原模型性能。

**标签**: #Diffusion 模型 #Stable Diffusion #高效生成 #高分辨率

## **Mini-Omni: 实时语音对话模型**

![](https://mmbiz.qlogo.cn/sz_mmbiz_jpg/NM6DecUSXYtWYIE9aUXFP1YiaWE4UoQCzibp3YN2g5WysNvYMxdwDIcD9cicIwX9ITvVyzrRdTXR1D0jco6oFLl1A/0?wx_fmt=jpeg&from=appmsg)

**概要**: Mini-Omni [5][6][7][8]是第一个开源的多模态大语言模型，支持端到端的实时语音交互。该模型可以同时生成文本和音频，并具备边生成边输出的能力。通过提出“Any Model Can Talk”方法，Mini-Omni 在保留语言理解能力的基础上，增强了语音交互性能。该模型还引入了 VoiceAssistant-400K 数据集，用于优化语音助手的生成任务。

**标签**：#多模态模型 #实时语音交互 #开源数据集

## **StyleTokenizer: 控制 Diffusion 模型的图像风格生成**

![](https://mmbiz.qlogo.cn/sz_mmbiz_jpg/NM6DecUSXYtWYIE9aUXFP1YiaWE4UoQCzt1iay5gWmsmIRqzWFyo8SI4QcM9crJl7zDxMn7l7X41aPOM3I79Bq2Q/0?wx_fmt=jpeg&from=appmsg)

**概要**: StyleTokenizer [9][10]是**支付宝**团队提出的一种基于单个图像样例来定义图像风格的零样本控制方法，用于控制  Diffusion  模型的生成过程。它通过对齐风格表示和文本表示，避免了以往图像生成中风格和文本控制间的冲突。为此，StyleTokenizer 还引入了一个名为 Style30k 的数据集，用于训练风格特征提取器，确保生成结果的风格准确性与一致性。

**标签**: #Diffusion 模型 #风格迁移 #图像生成 #风格控制 #零样本学习

## **HiPrompt: 强化 Diffusion 模型提示词优化框架**

![](https://mmbiz.qlogo.cn/sz_mmbiz_png/NM6DecUSXYtWYIE9aUXFP1YiaWE4UoQCzwvCJlfkAQcWZNd1zFERnhic62yGia46IIoeqVkiayicd2Bq2Tsdkia9TrNw/0?wx_fmt=png&from=appmsg)

**概要**: HiPrompt [11][12]是一个针对  Diffusion  模型的提示词优化框架，旨在通过分层提示词进行更高分辨率的图像生成。它通过全局与局部的提示词指导生成过程，减少对象重复与结构性失真问题。在逆去噪过程中，HiPrompt 将图像的低频与高频成分分开处理，使得生成图像在保持全局一致性的同时具有丰富的细节。

**标签**: #Diffusion 模型 #提示词优化 #高分辨率图像生成

## **Geometry Image Diffusion: 基于图像的高效文本生成 3D 模型材质**

![](https://mmbiz.qlogo.cn/sz_mmbiz_png/NM6DecUSXYtWYIE9aUXFP1YiaWE4UoQCzWsMvCL13J1dorn5INgQfmcDuTlMUicJfohPY7v1lG2f8ZuKKLAYtibiaQ/0?wx_fmt=png&from=appmsg)

**概要**: Geometry Image Diffusion [13]  是  **Unity 公司**研发的一个快速且数据高效的文本到 3D 模型材质生成方法，利用图像表示 3D 模型表面材质，避免复杂的 3D 架构。该方法结合了现有的 2D 文本到图像模型 Stable Diffusion，通过协作控制生成 3D 对象。这些生成的 3D 物体不仅具有语义上的分离部分，还包含内部结构，增强了其适用性和灵活性。

**标签**: #Diffusion  模型 #3D 生成 #文本到 3D #Unity

## **Guide-and-Rescale: 实现无调优高效图像编辑的自引导机制**

![](https://mmbiz.qlogo.cn/sz_mmbiz_png/NM6DecUSXYtWYIE9aUXFP1YiaWE4UoQCzcAicAdOickibyHvxJUwRWykRdP3QWWYdC0DHcfBVzqEC9UUPiaicBV8Fuaw/0?wx_fmt=png&from=appmsg)

**概要**: Guide-and-Rescale [14][15]提出了一种基于自引导机制的图像编辑方法，允许对真实图像进行多样的编辑操作，而无需对 Diffusion 模型进行微调或复杂的超参数调整。通过噪声重缩放技术，该方法在编辑质量和保持原始图像结构之间实现了良好的平衡，确保了高效且高质量的图像编辑。

**标签**: #图像编辑 #Diffusion 模型 #Tuning-free #自引导

### **参考链接**

1. DepthCrafter 项目 GitHub
2. DepthCrafter 项目论文
3. LinFusion 项目 GitHub
4. LinFusion 项目论文
5. Mini-Omni 项目 GitHub
6. Mini-Omni 项目论文
7. Mini-Omni 项目 HuggingFace 模型页面
8. Mini-Omni 项目 HuggingFace 演示页面
9. Style Tokenizer 项目 GitHub
10. Style Tokenizer 项目论文
11. HiPrompt 项目 GitHub
12. HiPrompt 项目论文
13. Geometry-Image-Diffusion 项目论文
14. Guide-and-Rescale 项目 GitHub
15. Guide-and-Rescale 项目论文
